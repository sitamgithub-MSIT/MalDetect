{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Y81dfPqkTe"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgSsZsLyqkTj"
      },
      "source": [
        "## Introduction: what is EfficientNet?\n",
        "\n",
        "EfficientNet, first introduced in [Tan and Le, 2019](https://arxiv.org/abs/1905.11946) is among the most efficient models (i.e. requiring least FLOPS for inference) that reaches State-of-the-Art accuracy on both imagenet and common image classification transfer learning tasks.\n",
        "\n",
        "The smallest base model is similar to [MnasNet](https://arxiv.org/abs/1807.11626), which reached near-SOTA with a significantly smaller model. By introducing a heuristic way to scale the model, EfficientNet provides a family of models (B0 to B7) that represents a good combination of efficiency and accuracy on a variety of scales. Such a scaling heuristics (compound-scaling, details see [Tan and Le, 2019](https://arxiv.org/abs/1905.11946)) allows the\n",
        "efficiency-oriented base model (B0) to surpass models at every scale, while avoiding extensive grid-search of hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08MW4AtwqkTm"
      },
      "source": [
        "## Setup and data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ODXQLlGqkTn"
      },
      "outputs": [],
      "source": [
        "# Required packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# tensorflow and keras imports\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "# tensorflow imports\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# IMG_SIZE is determined by model choice (EfficientNetB0)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4uwCePpqkTp"
      },
      "source": [
        "### Loading data\n",
        "\n",
        "Here we load data from [tensorflow_datasets](https://www.tensorflow.org/datasets). Malaria dataset is provided in TFDS as [malaria](https://www.tensorflow.org/datasets/catalog/malaria). It features 27,558 images that belong to 2 classes: parasitized and uninfected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYMTY98RqkTq"
      },
      "outputs": [],
      "source": [
        "# Dataset name\n",
        "dataset_name = \"malaria\"\n",
        "\n",
        "# Load the dataset split into train and test\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
        ")\n",
        "\n",
        "# Number of classes in the dataset\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOKDMEQxqkTr"
      },
      "source": [
        "When the dataset include images with various size, we need to resize them into a shared size. The malaria dataset comes with images of different sizes. Here we resize the images to the input size needed for EfficientNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvEY86KrqkTs"
      },
      "outputs": [],
      "source": [
        "# size of the train and test datasets\n",
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "# Resize images to the desired size (ResNet50 input size)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sOoeU_RqkTt"
      },
      "source": [
        "### Visualizing the data\n",
        "\n",
        "The following code shows the first 9 images with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz659SabqkTt"
      },
      "outputs": [],
      "source": [
        "def format_label(label):\n",
        "    \"\"\"\n",
        "    Formats the given label by extracting the second part of a hyphen-separated string.\n",
        "\n",
        "    Args:\n",
        "        label (int): The label to be formatted.\n",
        "\n",
        "    Returns:\n",
        "        str: The formatted label.\n",
        "\n",
        "    \"\"\"\n",
        "    string_label = label_info.int2str(label)\n",
        "    return string_label.split(\"-\")[1]\n",
        "\n",
        "\n",
        "# labels for the first 9 images in the dataset\n",
        "label_info = ds_info.features[\"label\"]\n",
        "\n",
        "# iterate through the dataset and plot the first 9 images\n",
        "for i, (image, label) in enumerate(ds_train.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "    plt.title(f\"{format_label(label)}\")\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hW4xYflqkTu"
      },
      "source": [
        "### Data augmentation\n",
        "\n",
        "We can use the preprocessing layers APIs for image augmentation. Here we randomly flip and rotate the input images. We also use random translation and contrast/brightness adjustment as data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWLA_qztqkTu"
      },
      "outputs": [],
      "source": [
        "# Image augmentation layers to be applied to the dataset\n",
        "img_augmentation_layers = [\n",
        "    layers.RandomRotation(factor=0.15),\n",
        "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    layers.RandomFlip(),\n",
        "    layers.RandomContrast(factor=0.1),\n",
        "]\n",
        "\n",
        "# Apply image augmentation layers to the dataset\n",
        "def img_augmentation(images):\n",
        "    \"\"\"\n",
        "    Apply image augmentation techniques to the given images.\n",
        "\n",
        "    Args:\n",
        "        images (numpy.ndarray): Input images to be augmented.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Augmented images.\n",
        "    \"\"\"\n",
        "    for layer in img_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPbi6yEfqkTv"
      },
      "source": [
        "Here we plot 9 examples of augmentation result of a given figure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa9HG3wkqkTv"
      },
      "outputs": [],
      "source": [
        "# plot the augmented images for the first 9 images in the dataset\n",
        "for image, label in ds_train.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        aug_img = img_augmentation(np.expand_dims(image.numpy(), axis=0))\n",
        "        aug_img = np.array(aug_img)\n",
        "        plt.imshow(aug_img[0].astype(\"uint8\"))\n",
        "        plt.title(f\"{format_label(label)}\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o-wMoPSqkTv"
      },
      "source": [
        "### Prepare inputs\n",
        "\n",
        "Once we verify the input data and augmentation are working correctly, we prepare dataset for training. The input data are resized to uniform `IMG_SIZE`. The labels are put into one-hot (a.k.a. categorical) encoding. The dataset is batched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1hCnHQ9qkTw"
      },
      "outputs": [],
      "source": [
        "def input_preprocess_train(image, label):\n",
        "    \"\"\"\n",
        "    Preprocesses the input image and label for training.\n",
        "\n",
        "    Args:\n",
        "        image (Tensor): The input image.\n",
        "        label (int): The label corresponding to the image.\n",
        "\n",
        "    Returns:\n",
        "        Tuple: A tuple containing the preprocessed image and one-hot encoded label.\n",
        "    \"\"\"\n",
        "    image = img_augmentation(image)\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def input_preprocess_test(image, label):\n",
        "    \"\"\"\n",
        "    Preprocesses the input image and label for testing.\n",
        "\n",
        "    Args:\n",
        "        image: The input image.\n",
        "        label: The label corresponding to the image.\n",
        "\n",
        "    Returns:\n",
        "        The preprocessed image and the one-hot encoded label.\n",
        "    \"\"\"\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing to the train dataset and batch the dataset for training\n",
        "ds_train = ds_train.map(input_preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Apply preprocessing to the test dataset and batch the dataset for testing / validation\n",
        "ds_test = ds_test.map(input_preprocess_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size=BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer learning from pre-trained weights\n",
        "\n",
        "Here we initialize the model with pre-trained ImageNet weights, and we train the model on our own dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizer Tuning\n",
        "\n",
        "To achieve optimal performance, we need to use a learning rate schedule instead of a single learning rate. Optimizer choice and tuning are important for model performance. We have used `Adam` optimizer with a learning rate schedule defined as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lr_warmup_cosine_decay(\n",
        "    global_step,\n",
        "    warmup_steps,\n",
        "    hold=0,\n",
        "    total_steps=0,\n",
        "    start_lr=0.0,\n",
        "    target_lr=1e-2,\n",
        "):\n",
        "    \"\"\"\n",
        "    Computes the learning rate using warmup and cosine decay.\n",
        "\n",
        "    Args:\n",
        "        global_step (int): The current global step.\n",
        "        warmup_steps (int): The number of warmup steps.\n",
        "        hold (int, optional): The number of steps to hold the learning rate after warmup. Defaults to 0.\n",
        "        total_steps (int, optional): The total number of steps. Defaults to 0.\n",
        "        start_lr (float, optional): The initial learning rate. Defaults to 0.0.\n",
        "        target_lr (float, optional): The target learning rate. Defaults to 1e-2.\n",
        "\n",
        "    Returns:\n",
        "        float: The computed learning rate.\n",
        "    \"\"\"\n",
        "    # Cosine decay\n",
        "    learning_rate = (\n",
        "        0.5\n",
        "        * target_lr\n",
        "        * (\n",
        "            1\n",
        "            + ops.cos(\n",
        "                math.pi\n",
        "                * ops.convert_to_tensor(\n",
        "                    global_step - warmup_steps - hold, dtype=\"float32\"\n",
        "                )\n",
        "                / ops.convert_to_tensor(\n",
        "                    total_steps - warmup_steps - hold, dtype=\"float32\"\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    warmup_lr = target_lr * (global_step / warmup_steps)\n",
        "    \n",
        "    if hold > 0:\n",
        "        learning_rate = ops.where(\n",
        "            global_step > warmup_steps + hold, learning_rate, target_lr\n",
        "        )\n",
        "    \n",
        "    learning_rate = ops.where(global_step < warmup_steps, warmup_lr, learning_rate)\n",
        "    return learning_rate\n",
        "\n",
        "\n",
        "class WarmUpCosineDecay(schedules.LearningRateSchedule):\n",
        "    \"\"\"\n",
        "    Learning rate schedule that combines warm-up, cosine decay, and hold phases.\n",
        "\n",
        "    Args:\n",
        "        warmup_steps (int): Number of steps for the warm-up phase.\n",
        "        total_steps (int): Total number of steps for the learning rate schedule.\n",
        "        hold (int): Number of steps to hold the learning rate after the warm-up phase.\n",
        "        start_lr (float, optional): Initial learning rate. Defaults to 0.0.\n",
        "        target_lr (float, optional): Target learning rate. Defaults to 1e-2.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup_steps, total_steps, hold, start_lr=0.0, target_lr=1e-2):\n",
        "        super().__init__()\n",
        "        self.start_lr = start_lr\n",
        "        self.target_lr = target_lr\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.total_steps = total_steps\n",
        "        self.hold = hold\n",
        "\n",
        "    def __call__(self, step):\n",
        "        lr = lr_warmup_cosine_decay(\n",
        "            global_step=step,\n",
        "            total_steps=self.total_steps,\n",
        "            warmup_steps=self.warmup_steps,\n",
        "            start_lr=self.start_lr,\n",
        "            target_lr=self.target_lr,\n",
        "            hold=self.hold,\n",
        "        )\n",
        "\n",
        "        return ops.where(step > self.total_steps, 0.0, lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Total number of images, warmup steps, and hold steps for the learning rate schedule\n",
        "total_images = 27558\n",
        "total_steps = (total_images // BATCH_SIZE) * EPOCHS\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "hold_steps = int(0.45 * total_steps)\n",
        "\n",
        "# Learning rate schedule\n",
        "schedule = WarmUpCosineDecay(\n",
        "    start_lr=0.05,\n",
        "    target_lr=1e-2,\n",
        "    warmup_steps=warmup_steps,\n",
        "    total_steps=total_steps,\n",
        "    hold=hold_steps,\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "optimizer_fn = optimizers.SGD(\n",
        "    weight_decay=5e-4,\n",
        "    learning_rate=schedule,\n",
        "    momentum=0.9,\n",
        ")\n",
        "\n",
        "# Loss function\n",
        "loss_fn = losses.BinaryCrossentropy(label_smoothing=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup Callbacks\n",
        "\n",
        "Callbacks are used to implement early stopping, save checkpoints, and log training information such as loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callbacks for the training process\n",
        "train_callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=2, restore_best_weights=True\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the model\n",
        "\n",
        "The first step to transfer learning is to freeze all layers and train only the top layers. Here, validation accuracy and loss will usually be better than training accuracy and loss. This indicates that the model has not yet overfit the training set and has generalized well to the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzpaVPfrqkTx"
      },
      "outputs": [],
      "source": [
        "def build_model(num_classes):\n",
        "    \"\"\"\n",
        "    Builds a model using EfficientNetB0 architecture for image classification.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): The number of classes for classification.\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: The compiled model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Input layer for the model with the given input shape\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    # Load the EfficientNetB0 model\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights of the model\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top layers of the model for classification\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile the model\n",
        "    model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_hist(history):\n",
        "    \"\"\"\n",
        "    Plots the model accuracy and loss for the training and validation sets.\n",
        "\n",
        "    Parameters:\n",
        "    history (keras.callbacks.History): The history object returned by the model.fit() function.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    # Plotting the model accuracy and loss for the training and validation sets\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "    \n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy']) \n",
        "    axs[0].plot(history.history['val_accuracy']) \n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy') \n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss']) \n",
        "    axs[1].plot(history.history['val_loss']) \n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss') \n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytzK-py_qkTy"
      },
      "source": [
        "\n",
        "Fit the model to the training data and validate using the validation data. We use number of epochs as 10, but the model will stop training when the validation loss stops improving. We use early stopping callback to achieve this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_4rW34DqkTy"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = build_model(num_classes=NUM_CLASSES)\n",
        "\n",
        "# Number of epochs for training\n",
        "epochs = 25  # @param {type: \"slider\", min:8, max:80}\n",
        "\n",
        "# Train the model and plot the training history\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
        "plot_hist(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2QVi-RrqkTz"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "- Model accuracy of EfficentNetB0 in the training set is 93.20% and in the validation set is 94.81%."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification_efficientnet_fine_tuning",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
